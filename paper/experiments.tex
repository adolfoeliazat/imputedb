\newcommand{\demorows}{10175}
\newcommand{\labexrows}{9813}

\section{Experiments}\label{sec:experiments}
To evaluate the performance of our approach,  we implemented
a prototype system in Java, following a traditional iterator model.
For our experiments we plan and execute queries
for two separate survey-based data sets, showing that our system
is well suited for early dataset exploration.

\subsection{Data sets} \label{subsec:datasets}
We collected three data sets our experiments.
For all data sets, we selected a subset of the original attributes.
We also enumerated strings and encoded them with an appropriate integer value.
\todo{describe all data transformations. jose?}

\subsubsection{CDC NHANES}
For our first set of experiments, we use survey data collected by the 
Centers for Disease Control and Prevention (CDC) in the United States. We
experiment on a set of tables collected as part of the 2013--2014 National
Health and Nutrition Examination Survey (NHANES), a series of studies
conducted by the CDC on a national sample of several thousand individuals~\cite{cdc-data}.
The data consists on survey responses, physical examinations, and laboratory
results, amongst others.

There are 6 tables in the NHANES data set. We use three tables for our experiments:

\begin{itemize}
	\item \emph{Demographics}: demographic information of subjects
	\item \emph{Examinations}: physical exam results
	\item \emph{Laboratory}: laboratory exam results
\end{itemize}

The original tables have a large number of attributes, in some cases providing more granular tests results or alternative metrics.
We focused on a subset of the attributes for each table to simplify the presentation and exploration of queries.
\Cref{table:nhanes-description} shows the attributes selected, along with the percentage of null values for each attribute.
For readability, we have replaced the NHANES variable names with self-explanatory attribute names.

\begin{table}
  \centering
  \begin{subtable}{0.5\textwidth}
    \centering
    \input{tables/cdc_demo}
    \caption{Demographics. \demorows{} rows.}
  \end{subtable}
  \par\medskip
  \begin{subtable}{0.5\textwidth}
    \centering
    \input{tables/cdc_labs}
    \caption{Laboratory Results. \labexrows{} rows.}
  \end{subtable}
  \par\medskip  
  \begin{subtable}{0.5\textwidth}
    \centering
    \input{tables/cdc_exams}
    \caption{Physical Results. \labexrows{} rows.}
  \end{subtable}
  \par\medskip  
  \caption{Missing value distribution for each table/attribute in CDC NHANES 2013--2014 data.}\label{table:nhanes-description} 
\end{table}

\subsubsection{freeCodeCamp 2016 New Coder Survey}
For our second set of experiments, we chose to use data collected
by freeCodeCamp as a part of a survey of new software developers
(both professional and amateur)~\cite{fcc-data}. freeCodeCamp is an open-source
community that helps users learn how to program. Their \textit{2016 New Coder Survey} consists of responses by over 15,000 people to 48 different
demographic and programming-related questions.
The survey targeted users who were related to coding organizations.

We use a version of the data that has been pre-processed, but where missing values remain.
\todobox{Give example of expected missing value}{However, many of the missing values are expected because the data has been de-normalized.}
The original dataset has 15,620 rows and 113 attributes.
We chose a subset of 17 attributes, shown in~\Cref{table:fcc-description}, along with the percentage of missing values.

\begin{table}
  \centering
  \input{tables/fcc}
  \caption{Missing values in freeCodeCamp Survey Data}\label{table:fcc-description} 
\end{table}

\subsubsection{American Community Survey}
For our final experiment, we introduce a simple aggregate query over data from the American Community Survey (ACS), which
provides a number of public data sets collected by the U.S. Census Bureau.
We used a cleaned version of the 2012 Public Use Microdata Sample (PUMS) data kindly provided by the authors of~\cite{akande2015empirical}.
Given that the data had been cleaned, we artificially dirtied it by removing 40\% of the values uniformly at random.
The final dataset consists of 671,153 rows and 37 integer columns.

\subsection{Queries}
We collected a set of queries (\Cref{fig:queries}) that we think are interesting to plan.
We believe that they could reasonably be written by a user in the course of data analysis.

The queries on the CDC NHANES data consist not only of projections and selections, but also interesting joins and aggregates.
Our aim was to craft meaningful queries
that would provide performance figures relevant to practitioners using
similar datasets.

Queries 1-4 are on the CDC data. In~\Cref{q1}, we calculate the average height for
users based on their income data. In~\Cref{q2}, we compare cholesterol levels for
individuals with low, medium, and high incomes spectrum and above a certain weight. In~\Cref{q3}, 
we extract the maximum blood lead levels for children under the age of 6
years. In~\Cref{q4}, we calculate the average systolic blood pressure, by gender, for
subjects with a body mass index indicating obesity. 

Queries 5-8 are on the freeCodeCamp data.
\Cref{q5} calculates the average income for survey participants, based on their bootcamp attendance.
\Cref{q6} estimates the average age of women from the United States who participated.
\Cref{q7} calculates the average amount of money survey participants with student debt spent on learning based on their school degree.
\Cref{q8} joins the freeCodeCamp data with a reference table provided by the World Bank which summarizes GDP per-capita across various countries~\cite{worldbank-data}.
The query calculates the average GDP per-capita of countries with and without bootcamp participants. 

\begin{table*}
  \todo{do we really need headers on these tables?}
  \centering
  \begin{subtable}{\linewidth}
    \input{queries-cdc}
    \caption{Queries on CDC data}\label{fig:queries-cdc}
  \end{subtable}
  \par\medskip
  \begin{subtable}{\linewidth}
    \input{queries-fcc}
    \caption{Queries on freeCodeCamp data}\label{fig:queries-fcc}
  \end{subtable}
  \par\medskip  
  \caption{Queries used in our experiments.}\label{fig:queries}
\end{table*}

%\begin{table*}
%  \centerfloat
%  \input{runtimes}
%    \caption{Base error, percent change in error and and running time for queries
%    with different imputation levels. Base error is the root-mean-square error (RMSE) between the query run on clean
%    data and the query run on dirty data without imputation. Change in error is relative to the base error.}
%  \label{fig:experiments}
%\end{table*}

All experiments were run on a single Amazon Web Services EC2 {\tt c4.xlarge} instance, with
four 2.9 GHz Intel Xeon E5--2666 v3 virtual CPUs and 7.5 GiB of main memory, on Debian Linux.

\Cref{fig:runtimes} shows a summary of the performance results. The first plot
shows average running times for \ProjectName{} plans in two configurations:
quality-optimized and runtime-optimized. The second plot shows, for comparison, the average
running times required for each query when performing imputation at the base tables.  In all
cases, running a query through \ProjectName{} is cheaper than imputing a single base table,
with performance improvement on a factor of ten\todo{give range of performance}. This performance differential means it is feasible
to explore multiple imputations operations (including more expensive operators) when using
\ProjectName{}, in contrast to the traditional approach of base table imputation.

\begin{figure}
  \todo{change this to a single graph of X-times faster than base approach}
  \begin{subfigure}{\linewidth}
    \includegraphics[width=\columnwidth]{figures/running_times_imputedb.png}
    \caption{Query runtimes with \ProjectName{}}\label{subfig:project-runtime-queries}
  \end{subfigure}
  ~
  \begin{subfigure}{\linewidth}
    \includegraphics[width=\columnwidth]{figures/running_times_base_tables.png}
    \caption{Query runtimes with imputation on base tables}\label{subfig:base-runtime-queries}
  \end{subfigure}
  \par\medskip
  \caption{Comparing \ProjectName{} runtimes for each query
    (\Cref{subfig:project-runtime-queries}) with the runtime for a query when base-table
    imputations are used (\Cref{subfig:base-runtime-queries})}\label{fig:runtimes}
\end{figure}

%\Cref{fig:plantimes} provides a summary of the planning times for each of the queries.
%We exclude the planning time for queries that impute at base table, as that requires no
%planning. 

In the median query across a variety of queries and choices of $\alpha$, planning
constituted 8.5 percent of total runtime. In all cases, the optimizer
returned a query plan within 40ms, with times roughly constant between levels of $\alpha$.

% The one-standard-deviation
%intervals around the mean planning time often overlap, suggesting the planning component is
%constant in $\alpha$.

%\begin{figure}
%\includegraphics[width=\columnwidth]{figures/planning_times_imputedb.png}
%\caption{Planning times for each query}
%\label{fig:plantimes}
%\end{figure}

\Cref{table:smape} shows the Symmetric-Mean-Absolute-Percentage-Error (SMAPE) for \ProjectName{}'s query results when compared to running imputation on the base tables and executing the query on the cleaned data \todo{SMAPE citation}.
Each query ran for 200 iterations \todo{iterations? is this for the imputation or is it the number of query re-runs?} in both settings and then results from the two approaches were paired up and compared tuple-wise.
We average tuple-wise absolute percentage deviations within each iteration of a query, and we report this value averaged over all iterations.
We can see that optimizing for quality indeed reduces the SMAPE of query results.
In general, the SMAPE relative to the base-imputation approach are low in all cases\todo{give actual value}, indicating that on-the-fly imputation produces similar results to imputation at the base tables.

\begin{table}
\todo{Consider switching to graph, or changing table layout..not very intuitive right now.}
\centering
\input{tables/perf_summary.tex}
\caption{Symmetric-Mean-Absolute-Percentage-Error for queries run under different $\alpha$
    parameterizations relative to results when imputing on base table. Values of $0.0$,
    $100.0$, or $NaN$ indicate uninformative values\todo{use one flag value (-) or explain why value is uninformative}.} %TODO MJS
\label{table:smape}
\end{table}

In many real-world cases, applying the imputation step at the base table is prohibitively expensive.
To illustrate the increasing difficulty of such an approach as datasets scale, we ran the following query over the ACS dataset:
\begin{lstlisting}
SELECT AVG(c0) FROM acs_dirty;
\end{lstlisting}
Imputing the base table and then running the query takes 75 minutes.
In contrast, \ProjectName{} executes a quality-optimized query plan in 7 seconds and a runtime-optimized plan in 1 second.
This highlights the benefit of using our system for early data exploration.
\end{figure}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
