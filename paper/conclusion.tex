\section{Conclusion}
As shown in \ProjectName{}, missing values and their imputation can be successfully integrated into the relational calculus and
existing cost-based plan optimization frameworks. We implement imputation actions, such as dropping or imputing values with a machine
learning technique, as operators in the algebra and use a simple, but effective, cost model to consider tradeoffs in 
information loss and runtime. We showed that different values for the tradeoff parameter can yield substantially
different plans, allowing the user to express their preferences for performance on a per-query basis.
Our experiments with \textit{CDC} and \textit{freeCodeCamp} survey-based datasets
showed that \ProjectName{} can be used successfully with real-world data, expressing standard SQL queries over data with missing values. 
We craft a series of realistic queries, meant to resemble the kind of questions an analyst might ask during
the data exploration phase. The plans selected for each query result in execution that
takes a fraction of the time compared to the standard approach of imputing on the entire base tables and
then formulating queries. Furthermore, the difference in query results between the two approaches is
shown to be minimal. Data analysts need not commit to a specific imputation strategy and can instead
vary this across queries.

We highlight the long history of dealing with missing data both in the statistical learning and database communities.
Similarly to existing work, we consider the impact of null values in databases and develop a simple set of invariants to 
successfully plan around them. In contrast to the statistical learning work, our emphasis is not on the specific algorithm
used to impute but rather on the timing of imputation in the execution of a query. In contrast to existing database work,
we incorporate imputation into a cost-based optimizer and hide any details
regarding missing values inside the system, allowing users to use traditional SQL and engage in normal workloads.
While prior work has incorporated operations such as prediction into their databases, this has been domain-specific
in some cases, and in others, they have not integrated these operations into the planner. The novelty
of our contribution lies in the formalization of missing value imputation for query planning, which results in performance
gains over traditional approaches. This approach acknowledges that different users performing different queries on the same
dataset will likely have varying imputation needs and that execution plans should appropriately reflect that variation.

\subsection{Future Work}
\todo{Jose: rewrite this}
\ProjectName{} opens up multiple avenues for further work. For instance, we
could extend our minimal/maximal imputation operators to consider global
information, such as the specific columns needed in operators higher up in the
query plan.  Our optimizer uses the same machine learning algorithm in all
instances of imputation operators. Integrating multiple possible algorithms
could allow for further fine-grained imputation, and honing the time complexity and
loss of these algorithms for an iterator model database could facilitate more
intelligent query plans and consistent interpretations of $\alpha$ across
strategies. For example, algorithms that learn in an online manner could
increase the efficiency of the system.  Furthermore, a multiple imputation
strategy could be followed for queries involving certain aggregates. Finally,
the underlying database for \ProjectName{} is far from a full-featured,
production database, so a natural step is to integrate imputation planning in a
widely-adopted production-quality database. This will likely expose further
opportunities for improvement.





%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
